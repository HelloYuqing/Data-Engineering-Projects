# Data-Engineering-Projects

                           Data Engineering Projects

<img width="783" alt="image" src="https://user-images.githubusercontent.com/69694512/211547136-4672ad2e-89db-498d-a7ac-132ef8f5f0ba.png">



## Project 1: Relational Databases - Data Modeling with PostgreSQL.
Developed a relational database using PostgreSQL to model user activity data for a music streaming app. 

* Created a relational database using PostgreSQL
* Developed a Star Schema database using optimized definitions of Fact and Dimension tables. 
* Built an ETL pipeline to optimize queries in order to understand what songs users listen to.

Proficiencies include: **Python, PostgreSql, Star Schema, ETL pipelines, Normalization**

## Project 2: Data Lake - Spark
Scaled up the current ETL pipeline by moving the data warehouse to a data lake. 

* Create an EMR Hadoop Cluster
* Further develop the ETL Pipeline copying datasets from S3 buckets, data processing using Spark and writing to S3 buckets using efficient partitioning and parquet formatting.
* Fast-tracking the data lake buildout using (serverless) AWS Lambda and cataloging tables with AWS Glue Crawler.

Technologies used: **Spark, S3, EMR, Athena, Amazon Glue, Parquet.**

## Project 3: Data Pipelines - Airflow
Automate the ETL pipeline and creation of data warehouse using Apache Airflow. 

* Using Airflow to automate ETL pipelines using Airflow, Python, Amazon Redshift.
* Writing custom operators to perform tasks such as staging data, filling the data warehouse, and validation through data quality checks.
* Transforming data from various sources into a star schema optimized for the analytics team's use cases.

Technologies used: **Apache Airflow, S3, Amazon Redshift, Python.**
