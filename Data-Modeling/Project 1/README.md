
## Introduction
A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. They'd like a data engineer to create a Postgres database with tables designed to optimize queries on song play analysis, and bring you on the project. Your role is to create a database schema and ETL pipeline for this analysis. So the first we need to do is analyze the data, let's see what inside

### Song Dataset
Songs dataset is a subset of Million Song Dataset.

Sample record:

```{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}```

### Log Dataset
Logs dataset is generated by Event Simulator.

Sample Record:

```{"artist": null, "auth": "Logged In", "firstName": "Walter", "gender": "M", "itemInSession": 0, "lastName": "Frye", "length": null, "level": "free", "location": "San Francisco-Oakland-Hayward, CA", "method": "GET","page": "Home", "registration": 1540919166796.0, "sessionId": 38, "song": null, "status": 200, "ts": 1541105830796, "userAgent": "\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"", "userId": "39"}```

## Design Schema
<img width="485" alt="image" src="https://user-images.githubusercontent.com/69694512/212037266-bd1c4a2e-ded5-48a5-a894-fdfd8c2784fe.png">

## Project Files
1. sql_queries.py -> contains sql queries for dropping and creating fact and dimension tables. Also, contains insertion query template.

2. create_tables.py -> contains code for setting up database. Running this file creates sparkifydb and also creates the fact and dimension tables.

3. etl.py -> read and process song_data and log_data

4. test.ipynb -> a notebook to connect to postgres db and validate the data loaded.

## Project Steps

